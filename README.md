# Tabular-Playground-Series---March-2022
Kaggle competition involving forecasting twelve-hours of traffic flow in a U.S. metropolis

I started this kaggle competition by creating additional features such as “roadway” and “daytime_id”. These features are basically a way to take all of the direction and time features and condense them into two features. Next I constructed many different visuals using matplotlib and seaborn. These visuals can be found in the attached notebook named “Useful Visuals”. In this notebook I also used techniques such as mutual information regression, lasso regression, permutation importance, and SHAP to determine that the roadway feature was the most informative feature. Next I decided to plot histograms of the congestion values of all of the roadways. Since most of the histograms showed a relatively normal distribution I figured that a simple approach such as simply taking the median of each roadway might give a relatively high accuracy. Before constructing my model I decided to take a closer look at some of the roadways that did not look normally distributed, and I decided to plot histograms of each of these specific roadways for each daytime_id to see how the distribution changed throughout the day. What I was able to conclude was that each distribution of congestion values resembled the distribution of the congestion value of 20 minutes prior. Therefore, for my model, I decided I would group the data on the roadway and daytime_id features and take the median. I would also create a new lag feature that would contain the congestion value from the previous 20 minute interval. My final predictions would then be a linear combination of the median and the 20 minute lag value. The linear combination was constructed using an ensemble of graident boosted trees such as catBoost regressor, adaboost regressor, bagging regressor, and hist gradient boosting regressor. My model was built and trained in the notebook named “Very Simple Using the Median”. My final prediction gave a mean squared error score of 5.964. I came in 47th out of 956 which placed me in the top 5% for this competition. 
